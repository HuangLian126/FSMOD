电气与电子工程学院

Influence of Sediment Characteristics on Heavy Metal Fraction Distribution in the Water-Level Fluctuation Zone of the Three Gorges Reservoir Area, China
IEEE Transactions on Circuits and Systems for Video Technology


尊敬的xxx领导同志：

您好！首先感激您在百忙之中阅读我的自荐材料！（简历见附件）

我是xx大学xx工程专业的一名20xx届毕业博士研究生，借此择业之际，我怀着饱满的热情和积极的`心态毛遂自荐。

我叫xxx，男，xx年xx月出生，xx人，xx大学xx工程学院20xx级结构工程专业博士研究生，已于20xx年xx月毕业。

在本科、硕士和博士研究生学习期间，努力学习，在各科考试中取得了优异的成绩，读博期间平均学习成绩达到xx分，较好地掌握了水利工程和建筑工程专业领域的基础理论和专业知识。积极参加各项教学和科研活动，参与教育部科技研究重点项目等5项课题的研究，读博期间发表专业论文18篇，其中被SCI录用8篇，具有较强的科研能力和科学创新能力。

在二十多年的学习和工作中，参加了多项水利工程和建筑工程的设计与管理工作，积累了丰富的实践经验，能够独立地进行工程设计与管理工作。同时通过硕士和博士两个阶段的系统研究，对土木工程方面的知识进行了全面系统地学习，具有更加宽广的知识面。

作为一个博士研究生，在了解和发挥自己优势的同时，我也不断地认识和纠正自己的不足，我个性开朗活泼，兴趣广泛，在学习和实践工作中，能够脚踏实地，吃苦耐劳，独立思考，按质按量的完成各项工作，并能够跟老师、同学和同事沟通合作，具备团队协作精神。我有信心地去面对即将到来的机遇与挑战。

我怀着一颗对事业执着追求的赤诚之心，真诚地向贵单位推荐自己。

最后祝贵单位的事业蒸蒸日上，蓬勃发展！

此致

敬礼！

自荐人：xxx

20xx年xx月xx日









http://rsc.cqupt.edu.cn/info/1124/2328.htm

Multispectral object detection (MOD),which incorporates additional information from the thermal images into object detection (OD) to cope with complex illumination conditions robustly, has attracted extensive interest. However, the training of existing MOD methods always demands a considerable amount of annotated data. Inspired by the concept of few-shot learning, we develop a novel few-shot multispectral object detection (FSMOD) task that aims to accomplish MOD using only a few annotated data from each category. Specifically, we first design a cross-modality interaction (CMI) module, which leverages different attention mechanisms to interact with the information from visible and thermal modalities in the process of backbone feature extraction. With the guidance of interaction process, the detector can extract more modality-specific backbone features. To improve the few-shot learning ability of the detector, we also design a semantic prototype metric (SPM) loss that integrates the semantic knowledge (i.e., word embeddings) into the optimization process of embedding space. Semantic knowledge provides stable category representation when visual information is insufficient. Extensive experiments on the customized FSMOD dataset demonstrate that the proposed method achieves state-of-the-art performance.


（1）书名：《机器学习》 清华大学出版社 ：108
（2）书名：《计算机视觉：算法与应用》 清华大学出版社 ：139
（3）书名：《2D计算机视觉：原理、算法及应用》 电子工业出版社 ：149
（4）书名：《计算机视觉算法：基于OpenCV的计算机应用开发》 机械工业出版社 ：69

深度学习框架PyTorch：入门与实践（第2版）

PyTorch深度学习和图神经网络

https://doi.org/10.48550/arXiv.1711.04340


Thirty-first Conference on Neural Information Processing Systems

Few-shot object detection with affinity relation reasoning

A few-shot bispectral object detection method has been proposed to address the reliance of the bispectral detector on paired visible and thermal images. This method utilizes a pseudo-feature transformation module to model the non-linear transformation from visible to thermal visual modality. During the training stage, the bispectral detector learns to synthesize expected pseudo-thermal features from visible features. The synthetic features are ensured to be meaningful through the use of pixel similarity and global consistency losses. Consequently, the bispectral detector only requires single visible images during the inference stage. In addition, a variational semantic hallucination module inspired by data augmentation is employed to enhance the class-discrimination of region of interest features. This module uses a multi-scale local similarity pyramid to achieve the expansion of region of interest features by leveraging the intra-class variance randomly sampled from the semantic knowledge. Experimental results demonstrate that the proposed method achieves state-of-the-art bispectral detection performance in a few-shot setting with access to only visible images.



不使用DaCL模块时所产生的误分类问题
使用DaCL模块时所缓解的误分类
本章节开发了稠密全局特征交互和双重对比学习模块，来提升基于双分支结构的小样本目标检测方法的性能。稠密全局特征交互模块通过查询图像和支持图像之间的信息交互赋予了检测器更可靠的新类别检测能力。双重对比学习模块使得特征具备良好的类内相似性和类间差异性，以缓解误分类问题。大量实验从定量、定性的角度论证了所提方法的有效性、鲁棒性。然而，视觉类别表征在小样本设定下存在不稳定性。此外，本章节的内容并未涉及热红外图像的处理。在未来，将引入额外的热红外图像和语义知识，进一步提升检测器在双光谱设定下的小样本学习能力

The semantic prototype-based metric branch considers semantic knowledge based on word embeddings as prototypes, to provide stable semantic representations for new category objects. It optimizes a discriminative embedding space to drive features to cluster around the semantic prototypes that belong to the same category.




重庆邮电大学通信与信息工程学院，博士研究生，专业：信息与通信工程
[1]	重庆邮电大学博士研究生人才培养项目，注意力感知的双光谱图像小样本目标检测方法研究 (No.BYJS202101)，2021.06-2023.06，主持.

[1] Huang L, Dai S, He Z. Few-Shot Object Detection with Semantic Enhancement and Semantic Prototype Contrastive Learning[J]. Knowledge-Based Systems, 2022, 252: 109411. (SCI期刊，中科院一区Top，IF: 8.139)
[2] Huang L, Dai S, He Z. Few-Shot Object Detection with Dense-Global Feature Interaction and Dual-Contrastive Learning[J]. Applied Intelligence, 2022. (SCI期刊，中科院二区，IF: 5.019)
[3] Huang L, Dai S, Huang T, Huang X, Wang H. Infrared Small Target Segmentation with Multiscale Feature Representation[J]. Infrared Physics &Technology, 2021, 116: 103755. (SCI期刊，中科院二区，IF: 2.997)
[4] Huang L, He Z, Feng X, Few-Shot Object Detection with Affinity Relation Reasoning[J]. Journal of Electronic Imaging, 2022, 31(3): 033016. (SCI期刊，中科院四区，IF: 0.945)




鲍宁海教授问：
（1）候选区域的生成和分类的标签是否是固定的？
答：检测器会使用候选区域生成网络生成候选区域，是固定的。
（2）如果候选区域质量很差，会影响后续的检测吗？
答：在检测的过程中，会根据标签信息对候选区域进行删除，只保留高质量的候选区域用于下一阶段的处理。
（3）第24页中，没有用箭头标明方向。
答：我会在答辩结束后进行修改。
（4）第33页中，右边的箭头没有交代内容、
答：我会在答辩结束后进行修改。
（5）第37页中，括号3里面的类别名称是否有必要列出来。
答：我会在答辩结束后，修改括号3里面的类别表示形式。


刘宏清教授问：
（1）请解释一下通道注意力的含义？
答：通道注意力的本质是一种对通道的加权。先得到每个通道的权重，再乘以每个通道





https://github.com/HuangLian126/LSPM

F. Team, et al., Free flir thermal dataset for algorithm training. URL https://www.flir.com/oem/adas/adas-dataset-form/



代老师，还有个情况向您汇报一下。我今天填成果的时候，偶然发现我博士同学2022年发表了一篇论文，但是和我2021发表的论文有很高的重复率，包括一些图和描述。他今年和我一起预答辩，我让他在毕业论文里面不能出现和我2021论文相似的内容，因为我在大论文里面也写了这些内容。这会不会影响我答辩？


Research on few-shot object detection method for bispectral image

Few-shot object detection with semantic enhancement and semantic prototype contrastive learning

Lian Huang, Shaosheng Dai, Ziqiang He

Knowledge-Based Systems 252 (2022) 109411


Published: 27 October 2022

DSP系统设计与应用
图错误!文档中没有指定样式的文字。 1 OD、BOD和FSBOD之间的概念化差别。（a）表示OD的训练过程依赖大量可见光图像；（b）表示BOD的训练过程依赖大量可见光和热红外图像；（c）表示FSMOD的训练过程依赖少量可见光和热红外图像
Fig.4-1 Conceptual comparisons of OD, BOD, and FSMOD. (a) Training process of OD demands a large number of visible images; (b) Training process of BD demands a large number of visible and thermal images; (c) Training process of FSBOD demands only a few of visible and thermal images

DSP原理是利用计算机或专用处理设备，以数字形式对信号进行采集、变换、滤波、估值、增强、压缩、识别等处理，以得到符合人们需要的信号形式。



图1-1 常见的目标检测任务。(a)人脸检测任务；(b)行人检测任务；(c)驾驶员行为检测任务
Fig.1-1 Common object detection tasks. (a) Face detection task; (b) Pedestrian detection task; (c) Driver behavior detection task

图1-2 目标检测研究现状
Fig.1-2 Research status of object detection


图1-4 小样本学习研究现状。(a)小样本图像分类；(b)小样本目标检测
Fig.1-4 Research status of few-shot learning. (a) Few-shot image classification; (b) Few-shot object detection


图1-5 论文各章节的组织结构
Fig.1-5 The organization of each chapter of this dissertation


图2-1可见光谱图像和热红外光谱图像的例子。(a)白天场景；(b)夜间场景
Fig.2-1 Examples of visible and thermal images. (a) Daytime scene; (b) Night scene

OD、MOD和FSMOD之间的概念化差别。（a）表示OD的训练过程依赖大量可见光图像；（b）表示MOD的训练过程依赖大量可见光和热红外图像；（c）表示FSMOD的训练过程依赖少量可见光和热红外图像
Fig.4-1 Conceptual comparisons of OD, MOD, and FSMOD. (a) Training process of OD demands a large number of visible images; (b) Training process of MOD demands a large number of visible and thermal images; (c) Training process of FSMOD demands only a few of visible and thermal images


图5-1 FSBOD的训练与推理流程。（a）表示FSBOD的训练阶段程；（b）表示FSBOD的推理阶段


基于跨模态交互和语义知识的小样本双光谱目标检测方法研究

基于跨模态迁移和语义边界对比的小样本双光谱目标检测方法研究

基于稠密全局特征交互和双重对比学习的小样本目标检测方法研究
Y. Song, Jia Li, X. Wang and X. Chen, “Single Image Dehazing Using Ranking Convolutional Neural Network,”in \textit{IEEE Transactions on Multimedia}, vol. 20, no. 6, 2018.
J. Liu, P. Liu, Y. Su, P. Jing and X. Yang,“Spatiotemporal Symmetric Convolutional Neural Network for Video Bit-Depth Enhancement,”in \textit{IEEE Transactions on Multimedia}, vol. 1 no. 9, 2019.
X. Zhang, X. Gao, W. Lu and L. He, “A gated peripheral-foveal convolutional neural network for unified image aesthetic prediction,” in \textit{IEEE Transactions on Multimedia}, vol. 21, no. 11, 2019.
K. Gu, Z. Xia, J. Qiao and W. Lin, “Deep dual-channel neural network for image-based smoke detection,”in \textit{IEEE Transactions on Multimedia}, vol. 22, no. 2, 2020.
M. Mesgaran and A. Ben Hamza, “Anisotropic graph convolutional network for semi-supervised learning,”in \textit{IEEE Transactions on Multimedia}, vol. 23, 2021.






T. I. Chen, Y. C. Liu, H. T. Su, Y. C. Chang, Y. H. Lin, J. F. Yeh, W. C. Chen and W. Hsu, “Dual-awareness attention for few-shot object detection,”in \textit{IEEE Transactions on Multimedia}, 2021.

Research on few-shot object detection method for bispectral image


X. Chen, H. Li, Q. Wu, F. Meng and H. Qiu, “Bal-R2CNN: High quality recurrent object detection with balance optimization,”in \textit{IEEE Transactions on Multimedia}, vol. 24, 2022.


T. Liu, K. M. Lam, R. Zhao and G. Qiu, “Deep cross-modal representation learning and distillation for illumination-invariant pedestrian detection,”in \textit{IEEE Transactions on Multimedia}, vol. 32, no. 1,  2022



C. Devaguptapu, N. Akolekar, M. M. Sharma and  V. N. Balasubramanian, “ Borrow from anywhere: pseudo multi-modal object detection in thermal imagery,”in \textit{Proceedings of IEEE Conference on Computer Vision and Pattern Recognition Workshops}, 2019.

KNOSYS-D-22-01443
Cross-modality Discrepant Interaction Network for RGB-D Salient Object Detection
MLPD: Multi-Label Pedestrian Detector in Multispectral Domain
Dear Editor,
We the undersigned declare that this manuscript entitled “文章标题” is original, has not been published before and is not currently being considered for publication elsewhere.
We would like to draw the attention of the Editor to the following publications of one or more of us that refer to aspects of the manuscript presently being submitted.  Where relevant copies of such publications are attached. 
We confirm that the manuscript has been read and approved by all named authors and that there are no other persons who satisfied the criteria for authorship but are not listed.  We further confirm that the order of authors listed in the manuscript has been approved by all of us.
We understand that the Corresponding Author is the sole contact for the Editorial process. He/she is responsible for communicating with the other authors about progress, submissions of revisions and final approval of proofs.  
Signed by all authors as follows:  作者1,作者2, 作者3
ORBIT: A Real-World Few-Shot Dataset for Teachable Object Recognition
Weakly Supervised Video Salient Object Detection
Calibrated RGB-D Salient Object Detection

AGPCNet: Attention-Guided Pyramid Context Networks for Infrared Small Target Detection

Multi-scale and Cross-scale Contrastive Learning for Semantic Segmentation

ReSTR: Convolution-free Referring Image Segmentation Using Transformers

Feature Selective Transformer for Semantic Image Segmentation
Scene Context-Aware Salient Object Detection

Boosting RGB-D Saliency Detection by Leveraging Unlabeled RGB Images

Region-aware Contrastive Learning for Semantic Segmentation
SwinNet: Swin Transformer drives edge-aware RGB-D and RGB-T salient object detection

The data that support the findings of this study are openly available at http://cocodataset.org and http://host.robots.ox.ac.uk/pascal/VOC/.


Infrared Patch-Image Model for Small Target Detection in a Single Image


Bi-directional Progressive Guidance Network for RGB-D Salient Object Detection


Suppress and Balance: A Simple Gated Network for Salient Object Detection

Siamese Network for RGB-D Salient Object Detection and Beyond

gh2561@columbia.edu

Table 1 The 1-shot mAP (%) for different support set loss functions on the Pascal VOC dataset of the first class split. base classes: the evaluated mAP (%) on the VOC07 test set that only contains base classes, all classes: the evaluated mAP (%) on test set that includes base and novel classes. novel classes: the evaluated mAP (%) on the test set that only contains novel classes.

Fig. 10 Sensitivity analysis on the change of support images. The box plot demonstrates the upper and lower quartiles of mAP.

For more details, readers can refer to https://github.com/HuangLian126/DGFIDaCL.

Table 2  Table 13. The runtime and memory of state-of-the-art few-shot object detector networks.

Since our proposed network relies on support images to assist the detection process, we analyze whether the detection results are sensitive to the change of support images. Besides, we also choose other meta-learning networks (FSRW, MetaRCNN, FsDetView and DCNet) to make a fair comparison. Following literature [x], we first train each network, and then test the network on the same query image for 100 times with different randomly sampled support images. The box plot of detection results is shown in Fig. 10. We can see that the detection results channel-attention-based networks (FSRW, MetaRCNN and FsDetView) are sensitive to the changes of support images. Although the support images are different in each iteration, our network can extract more accurate class representation with the help of spatial information and global context. As a result, the fluctuation of our detection results is the smallest.
 
Fig. 10 Sensitivity analysis on the change of support images. The box plot demonstrates the upper and lower quartiles of mAP.


We conduct an experiment in which models are tested on the same query image set for 100 times with different 3-shot randomly sampled support images in each iteration.


We conduct additional experiments to record the runtime and memory of different methods, as shown in Table 1. It is noting that all experiments are performed on a NVIDIA GeForce RTX 2080. Specifically, we report the inference speed in frame per second (FPS) and GPU memory occupation. We can see that DCNet and our method use the spatial-attention-based feature interaction to lead to more GPU occupation than channel-attention-based methods (FSRW, MetaRCNN and FsDetView). Therefore, we consider further reducing the GPU occupation of our method in the future. 


Zero-Shot Detection with Transferable Object Proposal Mechanish

Generalized Zero- and Few-Shot Learning via Aligned Variational Autoencoders

Rethinking semantic-visual alignment in zero-shot object detection via a softplus margin focal loss

https://drive.google.com/file/d/14muqZUdbpnYQ_30ZpAP9KqrVVHSkJOhU/view?usp=sharing

https://github.com/cvlab-stonybrook/vfd-iccv21

Infrared Physics & Technology 116 (2021) 103755

Mask R-CNN Kaiming He , Georgia Gkioxari, Piotr Dollar, and Ross Girshick

Information Sciences

He, K. , Gkioxari, G. , P Dollár, & Girshick, R. 

https://github.com/cvlab-stonybrook/vfd-iccv21
Few-Shot Segmentation via Cycle-Consistent Transformer

∆-encoder: an effective sample synthesis method for few-shot object recognition

BYJS202101
Learning Invariances with Contrastive Learning

Dear author,
        Hello! Your nice paper "Feature hallucination via Maximum A Posteriori for few-shot learning"  that samples novel features based on the estimated mean vectors and covariance matrices has inspired me a lot.
        However, I have a question why use the logistic regression classifier. Is it feasible to use traditional FC classifier?
        Looking forward to hearing from you.
Thank you and with best regards!
Yours sincerely,
Lian Huang


Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning


Reviewer #1: In the article, the author proposes a method for infrared small target segmentation using convolutional neural network. There are still two issues that need to be resolved.
1. In the third paragraph of the "Related Work" section, reference [33] was not found.
2. The author should use more figures to describe the effectiveness of the model in this article.

Cascade saccade machine learning network with hierarchical classes for traffic sign detection

KeepAugment: A Simple Information-Preserving Data Augmentation Approach

Negative Margin Matters: Understanding Margin in Few-shot Classification
Dense Relation Distillation with Context-aware Aggregation for Few-Shot Object Detection

Anchor-free Small-scale Multispectral Pedestrian Detection

Siamese Network for RGB-D Salient Object Detection and Beyond

The early LSTD [xxx] and RepMet [xx] employ the transfer learning framework to solve the problem of small sample target detection, which would face the problem of overfitting.

http://xlfd.cqupt.edu.cn/user/login.do
输入用户名（学号），
初始密码为A+学号，如用户名为D1901211456 密码为：AD1901211456。

MFNet: Towards Real-Time Semantic Segmentation for Autonomous Vehicles with Multi-Spectral Scenes

Dear Editor Zhenwei Shi,

Thank you for accept our manuscript, our reference number is the INFPHY_103755. A few days ago, Data Administrator Saranraj S sent me an email that asked me to revise the format of the formulas. I completed the revision as required and sent the revised manuscript to the email of Data Administrator Saranraj S (S.Saranraj@elsevier.com). So far, I do not get any response and do not know whether Data Administrator Saranraj S receives my email. Can you help me contact the Data Administrator Saranraj S ? I would appreciate your kindness very much.

Kind regards,
Lian Huang



bird 0.38883 -0.73101 -0.61076 -0.44162 -0.27135 0.12289 0.64843 -0.11904 0.40228 0.45893 0.62761 0.60071 -3.3078 0.081084 -0.26942 -0.29482 -0.060562 -0.25541 0.37728 -0.22934 -0.35133 0.83482 -0.020409 -0.71318 -0.76151 -0.086747 -0.81947 -0.48241 -0.061792 0.22282 -0.052594 0.27982 -0.3128 -0.82621 0.0089418 0.65678 0.2376 -0.96148 -0.067192 -0.097826 -0.61068 -0.74765 -0.87172 0.082443 0.41503 0.6483 -0.27395 0.48675 0.18884 0.77528